{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Ionosphere Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppKnB2tJtgAT"
      },
      "source": [
        "# Assignment: Ionosphere Data Problem\n",
        "\n",
        "### Dataset Description: \n",
        "\n",
        "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
        "\n",
        "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
        "\n",
        "### Attribute Information:\n",
        "\n",
        "- All 34 are continuous\n",
        "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
        "\n",
        " <br><br>\n",
        "\n",
        "<table border=\"1\"  cellpadding=\"6\">\n",
        "\t<tbody>\n",
        "        <tr>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">351</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Physical</p></td>\n",
        "        </tr>\n",
        "     </tbody>\n",
        "    </table>\n",
        "<table border=\"1\" cellpadding=\"6\">\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
        "            <td><p class=\"normal\">Integer,Real</p></td>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
        "            <td><p class=\"normal\">34</p></td>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
        "            <td><p class=\"normal\">N/A</p></td>\n",
        "        </tr>\n",
        "     </tbody>\n",
        "    </table>\n",
        "<table border=\"1\" cellpadding=\"6\">\t\n",
        "    <tbody>\n",
        "    <tr>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Classification</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
        "\t\t<td><p class=\"normal\">N/A</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">N/A</p></td>\n",
        "\t</tr>\n",
        "    </tbody>\n",
        "    </table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3kFGATGtgAk"
      },
      "source": [
        "# Load Data:\n",
        "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2bvve6suHFW"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jcwqWSNBTn8"
      },
      "source": [
        "- Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "dy7QzLQUvUBh",
        "outputId": "1929a819-9c62-4fad-d889-6d06b45051b0"
      },
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/ramsha275/ML_Datasets/main/ionosphere_data.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>-0.17755</td>\n",
              "      <td>0.59755</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>0.60536</td>\n",
              "      <td>-0.38223</td>\n",
              "      <td>0.84356</td>\n",
              "      <td>-0.38542</td>\n",
              "      <td>0.58212</td>\n",
              "      <td>-0.32192</td>\n",
              "      <td>0.56971</td>\n",
              "      <td>-0.29674</td>\n",
              "      <td>0.36946</td>\n",
              "      <td>-0.47357</td>\n",
              "      <td>0.56811</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature1  feature2  feature3  ...  feature33  feature34  label\n",
              "0         1         0   0.99539  ...    0.18641   -0.45300      g\n",
              "1         1         0   1.00000  ...   -0.13738   -0.02447      b\n",
              "2         1         0   1.00000  ...    0.56045   -0.38238      g\n",
              "3         1         0   1.00000  ...   -0.32382    1.00000      b\n",
              "4         1         0   1.00000  ...   -0.04608   -0.65697      g\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh00Ie-vDRDn"
      },
      "source": [
        "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column.\n",
        "- Shuffle the data if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G869zEhPvUo7",
        "outputId": "438b77c0-3810-4c46-f1bc-bcd52ec21520"
      },
      "source": [
        "data.isna().value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature1  feature2  feature3  feature4  feature5  feature6  feature7  feature8  feature9  feature10  feature11  feature12  feature13  feature14  feature15  feature16  feature17  feature18  feature19  feature20  feature21  feature22  feature23  feature24  feature25  feature26  feature27  feature28  feature29  feature30  feature31  feature32  feature33  feature34  label\n",
              "False     False     False     False     False     False     False     False     False     False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False    351\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OczTG5Nvv5uf",
        "outputId": "3c120ecc-e99d-4a0c-efe8-f8417a2465d5"
      },
      "source": [
        "data.isnull().value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature1  feature2  feature3  feature4  feature5  feature6  feature7  feature8  feature9  feature10  feature11  feature12  feature13  feature14  feature15  feature16  feature17  feature18  feature19  feature20  feature21  feature22  feature23  feature24  feature25  feature26  feature27  feature28  feature29  feature30  feature31  feature32  feature33  feature34  label\n",
              "False     False     False     False     False     False     False     False     False     False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False      False    351\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF_jiz6w5QSb",
        "outputId": "622a2b4e-cfe7-49f4-a117-756b1872a025"
      },
      "source": [
        "data.duplicated().value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    350\n",
              "True       1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhI13DO_5Y0W"
      },
      "source": [
        "data.drop_duplicates(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO4CO9co5htv"
      },
      "source": [
        "# Since Feature 2 columns doesnot have any correlation and value other then 0 we can drop it\n",
        "data.drop('feature2',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sChtdwo8CLcg"
      },
      "source": [
        "- Standardized the Input Variables. **Hint**: Centeralized the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fAUZgd95pGM"
      },
      "source": [
        "labels = data.label\n",
        "data.drop('label',axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgJ0N89DD2ZF"
      },
      "source": [
        "mean = data.mean(axis=0)\n",
        "data -= mean\n",
        "std = data.std(axis=0)\n",
        "data /= std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "ykAeqG5uFI9T",
        "outputId": "dcbdc9cb-4adb-4b20-fb60-ca0eacbc4ea7"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "      <td>3.500000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.790619e-16</td>\n",
              "      <td>2.851687e-16</td>\n",
              "      <td>-9.119689e-18</td>\n",
              "      <td>3.427417e-16</td>\n",
              "      <td>-1.714502e-16</td>\n",
              "      <td>-3.628843e-16</td>\n",
              "      <td>1.229969e-16</td>\n",
              "      <td>-8.631191e-16</td>\n",
              "      <td>-2.559857e-16</td>\n",
              "      <td>1.849314e-16</td>\n",
              "      <td>1.052333e-16</td>\n",
              "      <td>-2.413942e-16</td>\n",
              "      <td>5.630417e-18</td>\n",
              "      <td>-2.458351e-16</td>\n",
              "      <td>-1.867554e-16</td>\n",
              "      <td>-6.648650e-16</td>\n",
              "      <td>5.166502e-17</td>\n",
              "      <td>-1.021405e-16</td>\n",
              "      <td>-1.390852e-16</td>\n",
              "      <td>-1.953993e-16</td>\n",
              "      <td>-4.877051e-17</td>\n",
              "      <td>-3.698629e-16</td>\n",
              "      <td>4.916702e-18</td>\n",
              "      <td>1.516247e-16</td>\n",
              "      <td>3.179996e-17</td>\n",
              "      <td>-2.759697e-16</td>\n",
              "      <td>-1.076718e-16</td>\n",
              "      <td>4.123686e-16</td>\n",
              "      <td>7.981711e-17</td>\n",
              "      <td>-1.008717e-16</td>\n",
              "      <td>2.232341e-17</td>\n",
              "      <td>-8.120488e-17</td>\n",
              "      <td>-6.130017e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.904357e+00</td>\n",
              "      <td>-3.304632e+00</td>\n",
              "      <td>-2.362796e+00</td>\n",
              "      <td>-3.084606e+00</td>\n",
              "      <td>-2.419056e+00</td>\n",
              "      <td>-3.150739e+00</td>\n",
              "      <td>-2.147259e+00</td>\n",
              "      <td>-2.984541e+00</td>\n",
              "      <td>-2.439618e+00</td>\n",
              "      <td>-2.621033e+00</td>\n",
              "      <td>-2.332161e+00</td>\n",
              "      <td>-2.251376e+00</td>\n",
              "      <td>-2.206978e+00</td>\n",
              "      <td>-2.058360e+00</td>\n",
              "      <td>-2.334008e+00</td>\n",
              "      <td>-2.235880e+00</td>\n",
              "      <td>-2.002868e+00</td>\n",
              "      <td>-2.170182e+00</td>\n",
              "      <td>-1.877402e+00</td>\n",
              "      <td>-2.191320e+00</td>\n",
              "      <td>-1.943159e+00</td>\n",
              "      <td>-2.256275e+00</td>\n",
              "      <td>-1.784222e+00</td>\n",
              "      <td>-2.413701e+00</td>\n",
              "      <td>-1.823635e+00</td>\n",
              "      <td>-2.983060e+00</td>\n",
              "      <td>-1.701069e+00</td>\n",
              "      <td>-2.393544e+00</td>\n",
              "      <td>-1.910782e+00</td>\n",
              "      <td>-2.366339e+00</td>\n",
              "      <td>-1.936957e+00</td>\n",
              "      <td>-2.581576e+00</td>\n",
              "      <td>-2.163126e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.433265e-01</td>\n",
              "      <td>-3.413421e-01</td>\n",
              "      <td>-2.485773e-01</td>\n",
              "      <td>-3.604887e-01</td>\n",
              "      <td>-3.057630e-01</td>\n",
              "      <td>-6.739843e-01</td>\n",
              "      <td>-3.354767e-01</td>\n",
              "      <td>-8.283469e-01</td>\n",
              "      <td>-4.765567e-01</td>\n",
              "      <td>-7.976767e-01</td>\n",
              "      <td>-4.463784e-01</td>\n",
              "      <td>-6.454830e-01</td>\n",
              "      <td>-3.386764e-01</td>\n",
              "      <td>-5.281429e-01</td>\n",
              "      <td>-3.361751e-01</td>\n",
              "      <td>-6.192388e-01</td>\n",
              "      <td>-4.479696e-01</td>\n",
              "      <td>-5.749484e-01</td>\n",
              "      <td>-4.103875e-01</td>\n",
              "      <td>-5.531427e-01</td>\n",
              "      <td>-4.919077e-01</td>\n",
              "      <td>-6.015214e-01</td>\n",
              "      <td>-5.946351e-01</td>\n",
              "      <td>-6.862559e-01</td>\n",
              "      <td>-5.134830e-01</td>\n",
              "      <td>-4.971705e-01</td>\n",
              "      <td>-6.601286e-01</td>\n",
              "      <td>-6.584964e-01</td>\n",
              "      <td>-4.110400e-01</td>\n",
              "      <td>-6.180549e-01</td>\n",
              "      <td>-4.650660e-01</td>\n",
              "      <td>-6.698099e-01</td>\n",
              "      <td>-3.866285e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.433265e-01</td>\n",
              "      <td>4.631037e-01</td>\n",
              "      <td>-6.288430e-02</td>\n",
              "      <td>4.009943e-01</td>\n",
              "      <td>-2.021770e-01</td>\n",
              "      <td>3.607239e-01</td>\n",
              "      <td>-2.006236e-01</td>\n",
              "      <td>3.414646e-01</td>\n",
              "      <td>-3.327481e-01</td>\n",
              "      <td>3.423951e-01</td>\n",
              "      <td>-2.537731e-01</td>\n",
              "      <td>3.913782e-01</td>\n",
              "      <td>-1.274944e-01</td>\n",
              "      <td>3.955726e-01</td>\n",
              "      <td>-1.554114e-01</td>\n",
              "      <td>3.400358e-01</td>\n",
              "      <td>7.291133e-03</td>\n",
              "      <td>3.489391e-01</td>\n",
              "      <td>4.634961e-02</td>\n",
              "      <td>2.690010e-01</td>\n",
              "      <td>-1.603291e-02</td>\n",
              "      <td>2.789896e-01</td>\n",
              "      <td>1.089919e-01</td>\n",
              "      <td>2.730460e-01</td>\n",
              "      <td>1.103483e-01</td>\n",
              "      <td>3.156983e-01</td>\n",
              "      <td>8.968037e-02</td>\n",
              "      <td>2.076653e-01</td>\n",
              "      <td>5.501647e-02</td>\n",
              "      <td>1.632094e-01</td>\n",
              "      <td>7.397490e-03</td>\n",
              "      <td>1.199694e-01</td>\n",
              "      <td>-3.096219e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.433265e-01</td>\n",
              "      <td>7.176219e-01</td>\n",
              "      <td>3.398379e-01</td>\n",
              "      <td>7.644512e-01</td>\n",
              "      <td>4.748246e-01</td>\n",
              "      <td>8.503508e-01</td>\n",
              "      <td>6.364314e-01</td>\n",
              "      <td>8.694898e-01</td>\n",
              "      <td>7.314106e-01</td>\n",
              "      <td>8.525681e-01</td>\n",
              "      <td>6.622767e-01</td>\n",
              "      <td>8.898756e-01</td>\n",
              "      <td>5.689459e-01</td>\n",
              "      <td>8.788534e-01</td>\n",
              "      <td>5.236190e-01</td>\n",
              "      <td>8.942083e-01</td>\n",
              "      <td>4.002119e-01</td>\n",
              "      <td>8.612683e-01</td>\n",
              "      <td>3.093649e-01</td>\n",
              "      <td>9.159950e-01</td>\n",
              "      <td>3.478470e-01</td>\n",
              "      <td>9.091570e-01</td>\n",
              "      <td>4.211733e-01</td>\n",
              "      <td>8.808216e-01</td>\n",
              "      <td>4.503320e-01</td>\n",
              "      <td>8.892862e-01</td>\n",
              "      <td>4.042325e-01</td>\n",
              "      <td>8.762789e-01</td>\n",
              "      <td>3.581770e-01</td>\n",
              "      <td>8.845776e-01</td>\n",
              "      <td>3.980863e-01</td>\n",
              "      <td>8.916778e-01</td>\n",
              "      <td>3.359939e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.433265e-01</td>\n",
              "      <td>7.176219e-01</td>\n",
              "      <td>2.161473e+00</td>\n",
              "      <td>7.644512e-01</td>\n",
              "      <td>1.915315e+00</td>\n",
              "      <td>9.103637e-01</td>\n",
              "      <td>1.688155e+00</td>\n",
              "      <td>9.598458e-01</td>\n",
              "      <td>1.688808e+00</td>\n",
              "      <td>9.267930e-01</td>\n",
              "      <td>1.704523e+00</td>\n",
              "      <td>9.604104e-01</td>\n",
              "      <td>1.828895e+00</td>\n",
              "      <td>1.002074e+00</td>\n",
              "      <td>2.023185e+00</td>\n",
              "      <td>9.974026e-01</td>\n",
              "      <td>2.017450e+00</td>\n",
              "      <td>1.020285e+00</td>\n",
              "      <td>1.970101e+00</td>\n",
              "      <td>1.085034e+00</td>\n",
              "      <td>1.911093e+00</td>\n",
              "      <td>1.053232e+00</td>\n",
              "      <td>2.002205e+00</td>\n",
              "      <td>1.041189e+00</td>\n",
              "      <td>2.104032e+00</td>\n",
              "      <td>8.902109e-01</td>\n",
              "      <td>1.944909e+00</td>\n",
              "      <td>1.076551e+00</td>\n",
              "      <td>2.020815e+00</td>\n",
              "      <td>1.130229e+00</td>\n",
              "      <td>1.951752e+00</td>\n",
              "      <td>1.241956e+00</td>\n",
              "      <td>2.101202e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           feature1      feature3  ...     feature33     feature34\n",
              "count  3.500000e+02  3.500000e+02  ...  3.500000e+02  3.500000e+02\n",
              "mean   3.790619e-16  2.851687e-16  ... -8.120488e-17 -6.130017e-17\n",
              "std    1.000000e+00  1.000000e+00  ...  1.000000e+00  1.000000e+00\n",
              "min   -2.904357e+00 -3.304632e+00  ... -2.581576e+00 -2.163126e+00\n",
              "25%    3.433265e-01 -3.413421e-01  ... -6.698099e-01 -3.866285e-01\n",
              "50%    3.433265e-01  4.631037e-01  ...  1.199694e-01 -3.096219e-02\n",
              "75%    3.433265e-01  7.176219e-01  ...  8.916778e-01  3.359939e-01\n",
              "max    3.433265e-01  7.176219e-01  ...  1.241956e+00  2.101202e+00\n",
              "\n",
              "[8 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pSNAwwODn1W"
      },
      "source": [
        "- Encode labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TezS5vlF8kjj",
        "outputId": "03601d06-b1fe-4e19-b04b-6f88d57992af"
      },
      "source": [
        "temp = labels.replace({'g':1,'b':0})\n",
        "labels = temp\n",
        "labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    225\n",
              "0    125\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_qFpB8nDkPQ"
      },
      "source": [
        "- Split into 60 and 40 ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mNkBsEo6uRB",
        "outputId": "94612dd3-bf35-4565-c3e8-9f0ba0851fb2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data,test_data,train_labels,test_labels = train_test_split(data,labels,test_size=0.4)\n",
        "len(train_data),len(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210, 140)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTHdVApcNb6Q",
        "outputId": "edfad262-41ea-4b39-eff1-65f71431288b"
      },
      "source": [
        "test_data, validation_data , test_labels, validation_labels = train_test_split(test_data, test_labels, test_size = 0.4)\n",
        "len(test_data), len(validation_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc165t05IaGz"
      },
      "source": [
        "\n",
        "- Model : 1 hidden layers including 16 unit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH3ohqfAH4is"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9UJmetLIm7-"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(25, activation='relu', input_shape=(33,)))\n",
        "model.add(layers.Dense(16,activation='tanh'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIp8D1PHIco5"
      },
      "source": [
        "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h58ZMhC7IdEG"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8OFS1PGJWrk"
      },
      "source": [
        "- Train the Model with Epochs (100).\n",
        "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "- Prediction should be > **92%**\n",
        "- Evaluation Step\n",
        "- Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJSh11L0Jqaz",
        "outputId": "85d83da7-fc5e-4a1d-a04c-d3b256cbe95e"
      },
      "source": [
        "history = model.fit( train_data , train_labels , epochs=120 , batch_size=512 ,validation_data=(validation_data,validation_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.7963 - accuracy: 0.3905 - val_loss: 0.7253 - val_accuracy: 0.3929\n",
            "Epoch 2/120\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7335 - accuracy: 0.4286 - val_loss: 0.6891 - val_accuracy: 0.5179\n",
            "Epoch 3/120\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6935 - accuracy: 0.5095 - val_loss: 0.6620 - val_accuracy: 0.5714\n",
            "Epoch 4/120\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6631 - accuracy: 0.6190 - val_loss: 0.6398 - val_accuracy: 0.6607\n",
            "Epoch 5/120\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6383 - accuracy: 0.7143 - val_loss: 0.6208 - val_accuracy: 0.6964\n",
            "Epoch 6/120\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6169 - accuracy: 0.7429 - val_loss: 0.6042 - val_accuracy: 0.7321\n",
            "Epoch 7/120\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5982 - accuracy: 0.7571 - val_loss: 0.5894 - val_accuracy: 0.7321\n",
            "Epoch 8/120\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5813 - accuracy: 0.7762 - val_loss: 0.5760 - val_accuracy: 0.7321\n",
            "Epoch 9/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5660 - accuracy: 0.7952 - val_loss: 0.5637 - val_accuracy: 0.7143\n",
            "Epoch 10/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5518 - accuracy: 0.8143 - val_loss: 0.5524 - val_accuracy: 0.7500\n",
            "Epoch 11/120\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5387 - accuracy: 0.8190 - val_loss: 0.5420 - val_accuracy: 0.7679\n",
            "Epoch 12/120\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5264 - accuracy: 0.8238 - val_loss: 0.5323 - val_accuracy: 0.7679\n",
            "Epoch 13/120\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5147 - accuracy: 0.8333 - val_loss: 0.5233 - val_accuracy: 0.7857\n",
            "Epoch 14/120\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5036 - accuracy: 0.8571 - val_loss: 0.5149 - val_accuracy: 0.8214\n",
            "Epoch 15/120\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4930 - accuracy: 0.8524 - val_loss: 0.5070 - val_accuracy: 0.8214\n",
            "Epoch 16/120\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4830 - accuracy: 0.8524 - val_loss: 0.4994 - val_accuracy: 0.8214\n",
            "Epoch 17/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4733 - accuracy: 0.8524 - val_loss: 0.4922 - val_accuracy: 0.8214\n",
            "Epoch 18/120\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4640 - accuracy: 0.8571 - val_loss: 0.4852 - val_accuracy: 0.8214\n",
            "Epoch 19/120\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4550 - accuracy: 0.8619 - val_loss: 0.4786 - val_accuracy: 0.8214\n",
            "Epoch 20/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4463 - accuracy: 0.8667 - val_loss: 0.4723 - val_accuracy: 0.8393\n",
            "Epoch 21/120\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4378 - accuracy: 0.8667 - val_loss: 0.4662 - val_accuracy: 0.8571\n",
            "Epoch 22/120\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4296 - accuracy: 0.8667 - val_loss: 0.4604 - val_accuracy: 0.8571\n",
            "Epoch 23/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4216 - accuracy: 0.8667 - val_loss: 0.4548 - val_accuracy: 0.8571\n",
            "Epoch 24/120\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4138 - accuracy: 0.8667 - val_loss: 0.4494 - val_accuracy: 0.8571\n",
            "Epoch 25/120\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4062 - accuracy: 0.8714 - val_loss: 0.4441 - val_accuracy: 0.8571\n",
            "Epoch 26/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3986 - accuracy: 0.8762 - val_loss: 0.4391 - val_accuracy: 0.8571\n",
            "Epoch 27/120\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3913 - accuracy: 0.8762 - val_loss: 0.4343 - val_accuracy: 0.8571\n",
            "Epoch 28/120\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3841 - accuracy: 0.8762 - val_loss: 0.4296 - val_accuracy: 0.8571\n",
            "Epoch 29/120\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3771 - accuracy: 0.8762 - val_loss: 0.4252 - val_accuracy: 0.8571\n",
            "Epoch 30/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3701 - accuracy: 0.8762 - val_loss: 0.4209 - val_accuracy: 0.8393\n",
            "Epoch 31/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3634 - accuracy: 0.8762 - val_loss: 0.4167 - val_accuracy: 0.8393\n",
            "Epoch 32/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3568 - accuracy: 0.8762 - val_loss: 0.4126 - val_accuracy: 0.8393\n",
            "Epoch 33/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3503 - accuracy: 0.8810 - val_loss: 0.4087 - val_accuracy: 0.8393\n",
            "Epoch 34/120\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3440 - accuracy: 0.8857 - val_loss: 0.4050 - val_accuracy: 0.8393\n",
            "Epoch 35/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3378 - accuracy: 0.8857 - val_loss: 0.4014 - val_accuracy: 0.8393\n",
            "Epoch 36/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3317 - accuracy: 0.8857 - val_loss: 0.3980 - val_accuracy: 0.8393\n",
            "Epoch 37/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3258 - accuracy: 0.8952 - val_loss: 0.3947 - val_accuracy: 0.8393\n",
            "Epoch 38/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3199 - accuracy: 0.8952 - val_loss: 0.3916 - val_accuracy: 0.8393\n",
            "Epoch 39/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3141 - accuracy: 0.9000 - val_loss: 0.3886 - val_accuracy: 0.8393\n",
            "Epoch 40/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3085 - accuracy: 0.9000 - val_loss: 0.3858 - val_accuracy: 0.8393\n",
            "Epoch 41/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3029 - accuracy: 0.9000 - val_loss: 0.3830 - val_accuracy: 0.8393\n",
            "Epoch 42/120\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2975 - accuracy: 0.9000 - val_loss: 0.3804 - val_accuracy: 0.8393\n",
            "Epoch 43/120\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2922 - accuracy: 0.9000 - val_loss: 0.3780 - val_accuracy: 0.8393\n",
            "Epoch 44/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2869 - accuracy: 0.9048 - val_loss: 0.3757 - val_accuracy: 0.8393\n",
            "Epoch 45/120\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2817 - accuracy: 0.9095 - val_loss: 0.3734 - val_accuracy: 0.8393\n",
            "Epoch 46/120\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2766 - accuracy: 0.9095 - val_loss: 0.3713 - val_accuracy: 0.8393\n",
            "Epoch 47/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2716 - accuracy: 0.9143 - val_loss: 0.3694 - val_accuracy: 0.8393\n",
            "Epoch 48/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2667 - accuracy: 0.9238 - val_loss: 0.3677 - val_accuracy: 0.8393\n",
            "Epoch 49/120\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2619 - accuracy: 0.9286 - val_loss: 0.3660 - val_accuracy: 0.8393\n",
            "Epoch 50/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2571 - accuracy: 0.9286 - val_loss: 0.3644 - val_accuracy: 0.8571\n",
            "Epoch 51/120\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2524 - accuracy: 0.9286 - val_loss: 0.3629 - val_accuracy: 0.8571\n",
            "Epoch 52/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2479 - accuracy: 0.9286 - val_loss: 0.3616 - val_accuracy: 0.8571\n",
            "Epoch 53/120\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2433 - accuracy: 0.9333 - val_loss: 0.3603 - val_accuracy: 0.8571\n",
            "Epoch 54/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2389 - accuracy: 0.9381 - val_loss: 0.3591 - val_accuracy: 0.8571\n",
            "Epoch 55/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2345 - accuracy: 0.9381 - val_loss: 0.3580 - val_accuracy: 0.8571\n",
            "Epoch 56/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2301 - accuracy: 0.9381 - val_loss: 0.3572 - val_accuracy: 0.8571\n",
            "Epoch 57/120\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2259 - accuracy: 0.9381 - val_loss: 0.3563 - val_accuracy: 0.8571\n",
            "Epoch 58/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2217 - accuracy: 0.9381 - val_loss: 0.3557 - val_accuracy: 0.8571\n",
            "Epoch 59/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2177 - accuracy: 0.9381 - val_loss: 0.3550 - val_accuracy: 0.8571\n",
            "Epoch 60/120\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2137 - accuracy: 0.9429 - val_loss: 0.3543 - val_accuracy: 0.8571\n",
            "Epoch 61/120\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2098 - accuracy: 0.9429 - val_loss: 0.3535 - val_accuracy: 0.8571\n",
            "Epoch 62/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2060 - accuracy: 0.9429 - val_loss: 0.3529 - val_accuracy: 0.8571\n",
            "Epoch 63/120\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2022 - accuracy: 0.9476 - val_loss: 0.3522 - val_accuracy: 0.8571\n",
            "Epoch 64/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1985 - accuracy: 0.9524 - val_loss: 0.3517 - val_accuracy: 0.8571\n",
            "Epoch 65/120\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1949 - accuracy: 0.9524 - val_loss: 0.3511 - val_accuracy: 0.8571\n",
            "Epoch 66/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1913 - accuracy: 0.9524 - val_loss: 0.3506 - val_accuracy: 0.8571\n",
            "Epoch 67/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1877 - accuracy: 0.9524 - val_loss: 0.3500 - val_accuracy: 0.8571\n",
            "Epoch 68/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1842 - accuracy: 0.9524 - val_loss: 0.3498 - val_accuracy: 0.8571\n",
            "Epoch 69/120\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1808 - accuracy: 0.9524 - val_loss: 0.3492 - val_accuracy: 0.8750\n",
            "Epoch 70/120\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1774 - accuracy: 0.9524 - val_loss: 0.3492 - val_accuracy: 0.8750\n",
            "Epoch 71/120\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1741 - accuracy: 0.9524 - val_loss: 0.3490 - val_accuracy: 0.8750\n",
            "Epoch 72/120\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1708 - accuracy: 0.9524 - val_loss: 0.3486 - val_accuracy: 0.8750\n",
            "Epoch 73/120\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1676 - accuracy: 0.9571 - val_loss: 0.3485 - val_accuracy: 0.8750\n",
            "Epoch 74/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1644 - accuracy: 0.9571 - val_loss: 0.3484 - val_accuracy: 0.8750\n",
            "Epoch 75/120\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1613 - accuracy: 0.9571 - val_loss: 0.3481 - val_accuracy: 0.8750\n",
            "Epoch 76/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1582 - accuracy: 0.9571 - val_loss: 0.3481 - val_accuracy: 0.8750\n",
            "Epoch 77/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1552 - accuracy: 0.9571 - val_loss: 0.3476 - val_accuracy: 0.8750\n",
            "Epoch 78/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1522 - accuracy: 0.9667 - val_loss: 0.3473 - val_accuracy: 0.8750\n",
            "Epoch 79/120\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1493 - accuracy: 0.9667 - val_loss: 0.3471 - val_accuracy: 0.8750\n",
            "Epoch 80/120\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1464 - accuracy: 0.9667 - val_loss: 0.3471 - val_accuracy: 0.8750\n",
            "Epoch 81/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1436 - accuracy: 0.9667 - val_loss: 0.3469 - val_accuracy: 0.8750\n",
            "Epoch 82/120\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1408 - accuracy: 0.9667 - val_loss: 0.3467 - val_accuracy: 0.8750\n",
            "Epoch 83/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1380 - accuracy: 0.9667 - val_loss: 0.3466 - val_accuracy: 0.8750\n",
            "Epoch 84/120\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1353 - accuracy: 0.9667 - val_loss: 0.3464 - val_accuracy: 0.8750\n",
            "Epoch 85/120\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1326 - accuracy: 0.9714 - val_loss: 0.3465 - val_accuracy: 0.8750\n",
            "Epoch 86/120\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1300 - accuracy: 0.9714 - val_loss: 0.3464 - val_accuracy: 0.8750\n",
            "Epoch 87/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1274 - accuracy: 0.9714 - val_loss: 0.3464 - val_accuracy: 0.8750\n",
            "Epoch 88/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1248 - accuracy: 0.9762 - val_loss: 0.3465 - val_accuracy: 0.8750\n",
            "Epoch 89/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1223 - accuracy: 0.9762 - val_loss: 0.3463 - val_accuracy: 0.8750\n",
            "Epoch 90/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1198 - accuracy: 0.9762 - val_loss: 0.3462 - val_accuracy: 0.8750\n",
            "Epoch 91/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1174 - accuracy: 0.9762 - val_loss: 0.3462 - val_accuracy: 0.8750\n",
            "Epoch 92/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1150 - accuracy: 0.9762 - val_loss: 0.3463 - val_accuracy: 0.8750\n",
            "Epoch 93/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1126 - accuracy: 0.9762 - val_loss: 0.3465 - val_accuracy: 0.8750\n",
            "Epoch 94/120\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1104 - accuracy: 0.9762 - val_loss: 0.3465 - val_accuracy: 0.8750\n",
            "Epoch 95/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1081 - accuracy: 0.9762 - val_loss: 0.3467 - val_accuracy: 0.8750\n",
            "Epoch 96/120\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1059 - accuracy: 0.9762 - val_loss: 0.3468 - val_accuracy: 0.8750\n",
            "Epoch 97/120\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1037 - accuracy: 0.9762 - val_loss: 0.3475 - val_accuracy: 0.8750\n",
            "Epoch 98/120\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1015 - accuracy: 0.9762 - val_loss: 0.3479 - val_accuracy: 0.8750\n",
            "Epoch 99/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0994 - accuracy: 0.9762 - val_loss: 0.3480 - val_accuracy: 0.8750\n",
            "Epoch 100/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0974 - accuracy: 0.9762 - val_loss: 0.3480 - val_accuracy: 0.8750\n",
            "Epoch 101/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0953 - accuracy: 0.9762 - val_loss: 0.3487 - val_accuracy: 0.8750\n",
            "Epoch 102/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0933 - accuracy: 0.9762 - val_loss: 0.3490 - val_accuracy: 0.8750\n",
            "Epoch 103/120\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0914 - accuracy: 0.9762 - val_loss: 0.3491 - val_accuracy: 0.8750\n",
            "Epoch 104/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0894 - accuracy: 0.9810 - val_loss: 0.3491 - val_accuracy: 0.8750\n",
            "Epoch 105/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0875 - accuracy: 0.9810 - val_loss: 0.3493 - val_accuracy: 0.8750\n",
            "Epoch 106/120\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0856 - accuracy: 0.9810 - val_loss: 0.3504 - val_accuracy: 0.8750\n",
            "Epoch 107/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0838 - accuracy: 0.9810 - val_loss: 0.3502 - val_accuracy: 0.8750\n",
            "Epoch 108/120\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0819 - accuracy: 0.9810 - val_loss: 0.3505 - val_accuracy: 0.8750\n",
            "Epoch 109/120\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0802 - accuracy: 0.9810 - val_loss: 0.3511 - val_accuracy: 0.8750\n",
            "Epoch 110/120\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0784 - accuracy: 0.9857 - val_loss: 0.3507 - val_accuracy: 0.8750\n",
            "Epoch 111/120\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0767 - accuracy: 0.9857 - val_loss: 0.3515 - val_accuracy: 0.8750\n",
            "Epoch 112/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0750 - accuracy: 0.9857 - val_loss: 0.3513 - val_accuracy: 0.8750\n",
            "Epoch 113/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0733 - accuracy: 0.9857 - val_loss: 0.3522 - val_accuracy: 0.8750\n",
            "Epoch 114/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0716 - accuracy: 0.9857 - val_loss: 0.3523 - val_accuracy: 0.8750\n",
            "Epoch 115/120\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0700 - accuracy: 0.9857 - val_loss: 0.3531 - val_accuracy: 0.8750\n",
            "Epoch 116/120\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0685 - accuracy: 0.9952 - val_loss: 0.3532 - val_accuracy: 0.8750\n",
            "Epoch 117/120\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0669 - accuracy: 0.9952 - val_loss: 0.3540 - val_accuracy: 0.8750\n",
            "Epoch 118/120\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0655 - accuracy: 0.9952 - val_loss: 0.3545 - val_accuracy: 0.8571\n",
            "Epoch 119/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0640 - accuracy: 0.9952 - val_loss: 0.3548 - val_accuracy: 0.8571\n",
            "Epoch 120/120\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0625 - accuracy: 0.9952 - val_loss: 0.3551 - val_accuracy: 0.8571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYC-u2t7KbQV",
        "outputId": "d0f5b655-ff51-470e-ec10-bd2baae10ab3"
      },
      "source": [
        "evaluation = model.evaluate(test_data,test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.8690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "QBJPrnL4J58I",
        "outputId": "1d1a0d13-af57-446b-dfc1-1accedf286ef"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Fxefg5PtKP0f",
        "outputId": "a305e3e9-b2b0-40df-c233-ea57eaedc4ab"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7_yuFw-KwVL",
        "outputId": "959bce94-a84b-4627-c615-0ff6a707f8cc"
      },
      "source": [
        "print(f'{evaluation[1] * 100} % is the accuracy achieved on testing data by the created model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86.90476417541504 % is the accuracy achieved on testing data by the created model\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}